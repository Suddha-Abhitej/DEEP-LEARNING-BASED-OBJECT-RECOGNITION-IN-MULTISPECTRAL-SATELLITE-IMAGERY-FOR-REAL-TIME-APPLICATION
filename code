DATA EXPLORATION

# Importing few libraries
import os
import shutil
import random
from tqdm import tqdm
import numpy as np
import pandas as pd
import PIL
import seaborn as sns
import matplotlib.pyplot as plt 

DATASET = "../input/2756"
LABELS = os.listdir (DATASET)
print(LABELS) 

# plot class distributions of whole dataset
counts = {}
for 1 in LABELS:
counts[1] = len(os.listdir(os.path.join(DATASET, 1)))
plt.figure(figsize=(12, 6))
plt.bar(range(len(counts)), list(counts.values()), align="center’)
plt.xticks(range(len(counts)), list(counts.keys()), fontsize=12, rotation=40)
plt.xlabel('class label’, fontsize=13)
plt.ylabel('class size’, fontsize=13)
plt.title('Class Distribution’, fontsize=15) ; 

#The dataset is split into 10 classes of land cover. Each class varies in size, so I'll have to
#stratify later on when splitting the data into training, testing and validation sets.

img_paths = [os.path.join(DATASET, 1, 1+'_1088.jpg') for 1 in LABELS]
img_paths = img_paths + [os.path.join(DATASET, 1, 1+'_2608.jpg’) for 1 in LABELS]
def plot_sat_imgs(paths) :
plt.figure(figsize=(15, 8))
for i in range(2@):
plt.subplot(4, 5, i+1, xticks=[], yticks=[])
img = PIL.Image.open(paths[i], ‘r')
plt .imshow(np.asarray(img) )
plt.title(paths[i].split('/')[-2])
plot_sat_imgs(img_paths) 

import re
from sklearn.model_selection import StratifiedShuffleSplit
from keras.preprocessing.image import ImageDataGenerator
TRAIN_DIR = '../working/training’
TEST_DIR = '../working/testing’
BATCH_SIZE = 64
NUM_CLASSES=len(LABELS)
INPUT_SHAPE = (64, 64, 3)
CLASS_MODE = ‘categorical’
# create training and testing directories
for path in (TRAIN_DIR, TEST_DIR):
if not os.path.exists(path):
os.mkdir (path)
# create class label subdirectories in train and test
for 1 in LABELS:
if not os.path.exists(os.path.join(TRAIN_DIR, 1)):
os.mkdir(os.path.join(TRAIN_DIR, 1))
if not os.path.exists(os.path.join(TEST_DIR, 1)):
os.mkdir(os.path. join(TEST_DIR, 1)) 

# map each image path to their class label in ‘data’
data = {}
for
X=
y=
1 in LABELS:
for img in os. listdir(DATASET+’ /°+1):
data.update({os.path.join(DATASET, 1, img): 1})
pd.Series(list(data.keys()))
pd.get_dummies(pd.Series(data.values()))
split = Stratifiedshufflesplit(n_splits=1, test_size=8.2, random_state=69)
# split the list of image paths
for
ax
train_idx, test_idx in split.split(X, y):
train_paths = x[train_idx]
test_paths = x[test_idx]
# define a new path for each image depending on training or testing
new_train_paths = [re.sub(’\.\.\/input\/275@', ‘../working/training’, i) for i in train_paths]
new_test_paths = [re.sub('\.\.\/input\/275@", '../working/testing’, i) for i in test_paths]
train_path_map = list((zip(train_paths, new_train_paths) ))
test_path_map = list((zip(test_paths, new_test_paths)))
# move the files
print("moving training files..")
for i in tqdm(train_path_map):
if not os.path.exists(i[1]):
if not os.path.exists(re.sub(‘training’, ‘testing’, i[1])):
shutil.copy(i[@], i[1])
print(“moving testing files..")
for i in tqdm(test_path_map) :
if not os.path.exists(i[1]):
if not os.path.exists(re.sub(‘training’, ‘testing’, i[1])):
shutil.copy(i[@], i[1]) 

# Create a ImageDataGenerator Instance which can be used for data augmentation
train_gen = ImageDataGenerator(
rescale=1./255,
rotation_range=68,
width_shift_range=8.3,
height_shift_range=8.3,
shear_range=6.3,
zoom_range=8.3,
horizontal_flip=True,
validation_split=6.3
train_generator = train_gen.flow_from_directory(
directory=TRAIN_DIR,
target_size=(64, 64),
batch_size=BATCH_SIZE,
class_mode=CLASS_MODE,
subset='training',
color_mode='rgb',
shuffle=True,
seed=69 

valid_generator = train_gen.flow_from_directory(
directory=TRAIN_DIR,
target_size=(64, 64),
batch_size=BATCH_SIZE,
class_mode=CLASS_MODE,
subset='validation’,
color_mode='rgb‘
shuf fle=True,
seed=69
)
# test generator for evaluation purposes - no augmentations, just rescaling
test_gen = ImageDataGenerator(
rescale=1./255
)
test_generator = test_gen.flow_from_directory(
directory=TEST_DIR,
target_size=(64, 64),
batch_size=1,
class_mode=None,
color_mode='rgb',
shuffle=False,
seed=69
)

print(train_generator .class_indices) 

np.save('class_indices', train_generator.class_indices) 

import tensorflow as tf
from keras.models import Model
from keras.layers import Dense, Dropout, Flatten
from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from keras.optimizers import Adam
from keras.optimizers import Adagrad
from keras.applications import VGG16, VGG19
from keras.applications import ResNet5@, ResNet50V2, ResNet152V2
from keras.applications import InceptionV3, Xception
from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, fbeta_score, accuracy_score
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
try:
tf .config.experimental.set_visible_devices(gpus[@], ‘GPU')
logical_gpus = tf.config.experimental.list_logical_devices(‘GPU' )
print(len(gpus), “Physical GPUs,", len(logical_gpus), “Logical GPU")
except RuntimeError as e:
print(e)
tf.config.set_soft_device_placement (True) 

#USING DIFFERENT CNN MODELS

#for different CNN models we are using different setup of dense layers
def compile_model(cnn_base, input_shape, n_classes, optimizer, fine_tune=None) :
if (cnn_base == ‘ResNet5@') or (cnn_base == 'ResNet5@V2') or (cnn_base == ‘ResNet152V2'):
if cnn_base == ‘ResNet5@':
conv_base = ResNet5@(include_top=False,
weights="imagenet’,
input_shape=input_shape, pooling='avg' )
= 'ResNet50V2':
ResNet56V2(include_top=False,
weights='imagenet’,
input_shape=input_shape, pooling='avg' )
elif cnn_base
conv_base
else:
conv_base = ResNet152V2(include_top=False,
weights='imagenet’,
input_shape=input_shape, pooling='avg' )
top_model = conv_base.output
top_model = Dense(2048, activation='relu' )(top_model)
elif (cnn_base == ‘VGG16') or (cnn_base == ‘VGG19'):
if cnn_base == ‘VGG16':
conv_base = VGG16(include_top=False,
weights='imagenet’,
input_shape=input_shape, pooling='avg' )
else:
conv_base = VGG19(include_top=False,
weights='imagenet’,
input_shape=input_shape, pooling=' avg’ )
top_model = conv_base.output
top_model = Dense(2048, activation='relu' )(top_model)
output_layer = Dense(n_classes, activation='softmax' )(top_model) 

model = Model(inputs=conv_base.input, outputs=output_layer)
if type(fine_tune) == int:
for layer in conv_base.layers[fine_tune:]:
layer .trainable = True
else:
for layer in conv_base. layers:
layer.trainable = False
model.compile(optimizer=optimizer, loss='categorical_crossentropy',
metrics=['categorical_accuracy’ })
return model
def plot_history(history):
ace = history.history[‘categorical_accuracy’ ]
val_ace = history.history[‘val_categorical_accuracy'’ ]
loss = history.history['loss’ ]
val_loss = history.history[‘val_loss’ ]
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(acc)
pl1t.plot(val_acc)
plt.ylabel(‘ accuracy’ )
plt.xlabel(' epoch’ )
plt.legend(['train’', ‘val'], loc=‘upper left’)
plt.subplot(1, 2, 2)
plt.plot(loss)
plt.plot(val_loss)
plt.ylabel(‘loss’ )
plt.xlabel(‘ epoch’ )
plt.legend(['train', ‘val'], loc='upper left’)
plt.show();
def display_results(y_true, y_preds, class_labels):
results = pd.DataFrame(precision_recall_fscore_support(y_true, y_preds),
columns=class_labels) .T
results. rename(columns={@: ‘Precision’,
1: ‘Recall’,
2: ‘F-Score’,
3: ‘Support’}, inplace=True)
conf_mat = pd.DataFrame(confusion_matrix(y_true, y_preds),
columns=class_labels,
index=class_labels)
f2 = fbeta_score(y_true, y_preds, beta=2, average='micro’')
accuracy = accuracy_score(y_true, y_preds)
print(f"Accuracy: {accuracy}")
print(f"Global F2 Score: {f2}")
return results, conf_mat
def plot_predictions(y_true, y_preds, test_generator, class_indices):
fig = plt.figure(figsize=(28, 10))
for i, idx in enumerate(np.random.choice(test_generator.samples, size=20, replace=False)):
ax = fig.add_subplot(4, 5, i+ 1, xticks=[], yticks=[])
ax. imshow(np.squeeze(test_generator[idx]))
pred_idx = np.argmax(y_preds[idx])
true_idx = y_true[idx]
plt.tight_layout()
ax.set_title("{}\n({})”.format(class_indices[pred_idx], class_indices[true_idx]),
color=("green" if pred_idx == true_idx else "red”)) 


#VGG16
\vgg16_mode1 = compile_model('VGG16", INPUT_SHAPE, NUM_CLASSES, Adam(1r=1e-2), fine_tune=None)
vgg16_model 

train_generator.reset()
valid_generator.reset()
N_STEPS = train_generator.samples//BATCH_SIZE
N_VAL_STEPS = valid_generator.samples//BATCH_SIZE
N_EPOCHS = 188
# model callbacks
checkpoint = ModelCheckpoint(filepath=' ../working/model.weights.best.hdf5',
monitor='val_categorical_accuracy’,
save_best_only=True,
verbose=1)
early_stop = EarlyStopping(monitor='val_categorical_accuracy’,
patience=10,
restore_best_weights=True,
mode='max' ) 
vgg16_history = vgg16_model.fit_generator(train_generator,
steps_per_epoch=N_STEPS,
epochs=15,
callbacks=[early_stop, checkpoint],
validation_data=valid_generator,
validation_steps=N_VAL_STEPS) 

#VGG19
vgg19_model = compile_model('VGG19', INPUT_SHAPE, NUM_CLASSES, Adam(lr=1le-2), fine_tune=None)
vgg19_model.summary() 
train_generator .reset()
valid_generator.reset()
N_STEPS = train_generator.samples//BATCH_SIZE
N_VAL_STEPS = valid_generator.samples//BATCH_SIZE
N_EPOCHS = 180
# model callbacks
checkpoint = ModelCheckpoint(filepath='../working/model.weights.best.hdf5',
monitor='val_categorical_accuracy’,
save_best_only=True,
verbose=1 )
early_stop = EarlyStopping(monitor='val_categorical_accuracy’,
patience=18,
restore_best_weights=True,
mode='max' )
 vgg19_history = vgg19_model .fit_generator(train_generator,
steps_per_epoch=N_STEPS,
epochs=15,
callbacks=[early_stop, checkpoint],
validation_data=valid_generator,
validation_steps=N_VAL_STEPS) 

#RESNET50
resnet5@_model = compile_model(*ResNetS@°, INPUT_SHAPE, NUM_CLASSES, Adam(1r=1e-2), fine_tune=None)
resnet5@_model. summary () 
train_generator.reset()
valid_generator.reset()
N_STEPS = train_generator.samples//BATCH_SIZE
N_VAL_STEPS = valid_generator.samples//BATCH_SIZE
N_EPOCHS = 160
# model callbacks
checkpoint = ModelCheckpoint(filepath='../working/model.weights.best.hdf5',
monitor='val_categorical_accuracy’,
save_best_only=True,
verbose=1)
early_stop = EarlyStopping(monitor='val_categorical_accuracy’,
patience=18,
restore_best_weights=True,
mode='max' )
reduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5,
patience=3, min_lr=0.80001) 
resnet5@_history = resnetS@_model .fit_generator(train_generator,
steps_per_epoch=N_STEPS,
epochs=25,
callbacks=[early_stop, checkpoint, reduce_lr],
validation_data=valid_generator,
validation_steps=N_VAL_STEPS) 

#RESONET50V2
resnet5@V2_model = compile_model('ResNet5@V2', INPUT_SHAPE, NUM_CLASSES, Adam(1r=1e-2), fine_tune=None)
resnet50V2_model.summary() 
train_generator .reset()
valid_generator .reset()
N_STEPS = train_generator.samples//BATCH_SIZE
N_VAL_STEPS = valid_generator.samples//BATCH_SIZE
N_EPOCHS = 108
# model callbacks
checkpoint = ModelCheckpoint(filepath=' ../working/model.weights.best.hdf5',
monitor='val_categorical_accuracy’,
save_best_only=True,
verbose=1)
early_stop = EarlyStopping(monitor='val_categorical_accuracy’,
patience=18,
restore_best_weights=True,
mode=' max’ ) 
resnet5@V2_history = resnet5@V2_model.fit_generator(train_generator,
steps_per_epoch=N_STEPS
epochs=15,
callbacks=[early_stop, checkpoint],
validation_data=valid_generator,
validation_steps=N_VAL_STEPS) 
